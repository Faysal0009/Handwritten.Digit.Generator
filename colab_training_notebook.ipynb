{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f076431d",
   "metadata": {},
   "source": [
    "# üö® URGENT: 40-MINUTE SUBMISSION DEADLINE üö®\n",
    "\n",
    "## ‚ö° QUICK START GUIDE\n",
    "\n",
    "**IMMEDIATE ACTIONS:**\n",
    "1. **üéØ Set GPU NOW**: Runtime ‚Üí Change runtime type ‚Üí T4 GPU ‚Üí Save\n",
    "2. **‚ñ∂Ô∏è Run ALL cells** in order (takes ~25 minutes total)\n",
    "3. **üì• Download model** when training completes\n",
    "4. **üöÄ Deploy to Streamlit Cloud** while training runs\n",
    "\n",
    "**OPTIMIZED SETTINGS:**\n",
    "- ‚úÖ Reduced to **15 epochs** (was 50)\n",
    "- ‚úÖ Increased **batch size** to 256\n",
    "- ‚úÖ Higher **learning rate** for faster convergence\n",
    "- ‚úÖ **Total time: ~25 minutes** (fits in 40-minute deadline)\n",
    "\n",
    "**PARALLEL TASKS:**\n",
    "- Start training NOW\n",
    "- While training runs, set up GitHub repo\n",
    "- Upload your other files to GitHub\n",
    "- Prepare Streamlit Cloud deployment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd22bd4",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Digit Generation Training\n",
    "## Conditional GAN Training on Google Colab with T4 GPU\n",
    "\n",
    "**Instructions:**\n",
    "1. Make sure Runtime ‚Üí Change runtime type ‚Üí T4 GPU is selected\n",
    "2. Run all cells in order\n",
    "3. Training will take about 30-45 minutes\n",
    "4. Download the final `generator_model.pth` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4911f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è GPU not available. Please change runtime type to T4 GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73834a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (if needed)\n",
    "!pip install torch torchvision matplotlib numpy pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780439f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model.py file\n",
    "%%writefile model.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim=100, num_classes=10):\n",
    "        super(Generator, self).__init__()\n",
    "        self.noise_dim = noise_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Label embedding\n",
    "        self.label_embedding = nn.Embedding(num_classes, 50)\n",
    "        \n",
    "        # Generator network\n",
    "        self.fc1 = nn.Linear(noise_dim + 50, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 1024)\n",
    "        self.fc4 = nn.Linear(1024, 28 * 28)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, noise, labels):\n",
    "        # Embed labels\n",
    "        label_embed = self.label_embedding(labels)\n",
    "        \n",
    "        # Concatenate noise and label embedding\n",
    "        x = torch.cat([noise, label_embed], dim=1)\n",
    "        \n",
    "        # Forward pass\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.tanh(self.fc4(x))\n",
    "        \n",
    "        # Reshape to image format\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Label embedding\n",
    "        self.label_embedding = nn.Embedding(num_classes, 50)\n",
    "        \n",
    "        # Discriminator network\n",
    "        self.fc1 = nn.Linear(28 * 28 + 50, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, images, labels):\n",
    "        # Flatten images\n",
    "        images = images.view(-1, 28 * 28)\n",
    "        \n",
    "        # Embed labels\n",
    "        label_embed = self.label_embedding(labels)\n",
    "        \n",
    "        # Concatenate image and label embedding\n",
    "        x = torch.cat([images, label_embed], dim=1)\n",
    "        \n",
    "        # Forward pass\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "def create_models():\n",
    "    \"\"\"Create and return generator and discriminator models\"\"\"\n",
    "    generator = Generator()\n",
    "    discriminator = Discriminator()\n",
    "    return generator, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357383a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from model import Generator, Discriminator\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters - OPTIMIZED FOR FAST TRAINING (40 MINUTES)\n",
    "BATCH_SIZE = 256  # Increased for faster training\n",
    "LEARNING_RATE = 0.0003  # Slightly higher for faster convergence\n",
    "NUM_EPOCHS = 15  # Reduced from 50 to 15 for speed\n",
    "NOISE_DIM = 100\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "print(f\"‚ö° FAST TRAINING Configuration:\")\n",
    "print(f\"- Batch size: {BATCH_SIZE} (larger for speed)\")\n",
    "print(f\"- Learning rate: {LEARNING_RATE} (higher for faster convergence)\")\n",
    "print(f\"- Epochs: {NUM_EPOCHS} (reduced for time constraint)\")\n",
    "print(f\"- Estimated training time: {NUM_EPOCHS * 1.5:.0f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67af69b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset loaded: {len(train_dataset)} training samples\")\n",
    "print(f\"Number of batches: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c22701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "generator = Generator(NOISE_DIM, NUM_CLASSES).to(device)\n",
    "discriminator = Discriminator(NUM_CLASSES).to(device)\n",
    "\n",
    "# Loss function and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "\n",
    "print(f\"Generator parameters: {sum(p.numel() for p in generator.parameters()):,}\")\n",
    "print(f\"Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}\")\n",
    "print(\"Models initialized and moved to GPU!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b16062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with progress tracking - OPTIMIZED FOR SPEED\n",
    "def train_gan():\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    # Lists to track losses\n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        epoch_g_loss = 0\n",
    "        epoch_d_loss = 0\n",
    "        \n",
    "        for i, (real_images, real_labels) in enumerate(train_loader):\n",
    "            batch_size = real_images.size(0)\n",
    "            real_images = real_images.to(device)\n",
    "            real_labels = real_labels.to(device)\n",
    "            \n",
    "            # Labels for real and fake data\n",
    "            real_target = torch.ones(batch_size, 1).to(device)\n",
    "            fake_target = torch.zeros(batch_size, 1).to(device)\n",
    "            \n",
    "            # Train Discriminator\n",
    "            optimizer_D.zero_grad()\n",
    "            \n",
    "            # Real data\n",
    "            real_output = discriminator(real_images, real_labels)\n",
    "            real_loss = criterion(real_output, real_target)\n",
    "            \n",
    "            # Fake data\n",
    "            noise = torch.randn(batch_size, NOISE_DIM).to(device)\n",
    "            fake_labels = torch.randint(0, NUM_CLASSES, (batch_size,)).to(device)\n",
    "            fake_images = generator(noise, fake_labels)\n",
    "            fake_output = discriminator(fake_images.detach(), fake_labels)\n",
    "            fake_loss = criterion(fake_output, fake_target)\n",
    "            \n",
    "            # Total discriminator loss\n",
    "            d_loss = real_loss + fake_loss\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            # Train Generator\n",
    "            optimizer_G.zero_grad()\n",
    "            \n",
    "            # Generate fake images and get discriminator output\n",
    "            fake_output = discriminator(fake_images, fake_labels)\n",
    "            g_loss = criterion(fake_output, real_target)\n",
    "            \n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            # Accumulate losses\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            epoch_d_loss += d_loss.item()\n",
    "            \n",
    "            # Print progress less frequently for speed\n",
    "            if i % 50 == 0:  # Reduced from 100 to 50\n",
    "                print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Step [{i+1}/{len(train_loader)}], '\n",
    "                      f'D_loss: {d_loss.item():.4f}, G_loss: {g_loss.item():.4f}')\n",
    "        \n",
    "        # Track average losses\n",
    "        avg_g_loss = epoch_g_loss / len(train_loader)\n",
    "        avg_d_loss = epoch_d_loss / len(train_loader)\n",
    "        g_losses.append(avg_g_loss)\n",
    "        d_losses.append(avg_d_loss)\n",
    "        \n",
    "        print(f'‚úÖ Epoch [{epoch+1}/{NUM_EPOCHS}] completed - Avg D_loss: {avg_d_loss:.4f}, Avg G_loss: {avg_g_loss:.4f}')\n",
    "        \n",
    "        # Save sample images every 5 epochs (reduced from 10)\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            save_sample_images(epoch + 1)\n",
    "    \n",
    "    return g_losses, d_losses\n",
    "\n",
    "def save_sample_images(epoch):\n",
    "    \"\"\"Save sample generated images\"\"\"\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        # Generate one image for each digit\n",
    "        noise = torch.randn(10, NOISE_DIM).to(device)\n",
    "        labels = torch.arange(0, 10).to(device)\n",
    "        fake_images = generator(noise, labels)\n",
    "        \n",
    "        # Denormalize images\n",
    "        fake_images = fake_images * 0.5 + 0.5\n",
    "        \n",
    "        # Create subplot\n",
    "        fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "        for i in range(10):\n",
    "            row = i // 5\n",
    "            col = i % 5\n",
    "            axes[row, col].imshow(fake_images[i].cpu().squeeze(), cmap='gray')\n",
    "            axes[row, col].set_title(f'Digit {i}')\n",
    "            axes[row, col].axis('off')\n",
    "        \n",
    "        plt.suptitle(f'Generated Images - Epoch {epoch}', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    generator.train()\n",
    "\n",
    "print(\"‚ö° FAST Training functions defined. Ready to start training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7162122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training - FAST MODE FOR SUBMISSION DEADLINE\n",
    "print(\"üöÄ Starting FAST GAN training...\")\n",
    "print(\"‚è∞ OPTIMIZED FOR 40-MINUTE DEADLINE\")\n",
    "print(\"This will take approximately 20-25 minutes on T4 GPU\")\n",
    "print(\"Sample images will be shown every 5 epochs\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "g_losses, d_losses = train_gan()\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = (end_time - start_time) / 60\n",
    "\n",
    "print(f\"\\nüéâ Training completed in {training_time:.1f} minutes!\")\n",
    "print(\"üöÄ Ready for deployment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8fee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(generator.state_dict(), 'generator_model.pth')\n",
    "print(\"‚úÖ Model saved as 'generator_model.pth'\")\n",
    "\n",
    "# Plot training losses\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(g_losses, label='Generator Loss')\n",
    "plt.plot(d_losses, label='Discriminator Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Losses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Generate final test images\n",
    "plt.subplot(1, 2, 2)\n",
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    # Generate 5 images of digit 7 as final test\n",
    "    noise = torch.randn(5, NOISE_DIM).to(device)\n",
    "    labels = torch.full((5,), 7).to(device)  # Generate digit 7\n",
    "    test_images = generator(noise, labels)\n",
    "    test_images = test_images * 0.5 + 0.5\n",
    "    \n",
    "    # Show the 5 generated images\n",
    "    for i in range(5):\n",
    "        plt.subplot(2, 5, i + 6)\n",
    "        plt.imshow(test_images[i].cpu().squeeze(), cmap='gray')\n",
    "        plt.title(f'Generated 7 #{i+1}')\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Training summary:\")\n",
    "print(f\"Final Generator Loss: {g_losses[-1]:.4f}\")\n",
    "print(f\"Final Discriminator Loss: {d_losses[-1]:.4f}\")\n",
    "print(f\"Total training epochs: {NUM_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b44f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final test: Generate images for all digits\n",
    "print(\"üéØ Final Test: Generating images for all digits (0-9)\")\n",
    "\n",
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    # Generate 2 images for each digit\n",
    "    fig, axes = plt.subplots(2, 10, figsize=(20, 4))\n",
    "    \n",
    "    for digit in range(10):\n",
    "        noise = torch.randn(2, NOISE_DIM).to(device)\n",
    "        labels = torch.full((2,), digit).to(device)\n",
    "        digit_images = generator(noise, labels)\n",
    "        digit_images = digit_images * 0.5 + 0.5\n",
    "        \n",
    "        for i in range(2):\n",
    "            axes[i, digit].imshow(digit_images[i].cpu().squeeze(), cmap='gray')\n",
    "            axes[i, digit].set_title(f'Digit {digit}')\n",
    "            axes[i, digit].axis('off')\n",
    "    \n",
    "    plt.suptitle('Final Generated Images - All Digits', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Model training and testing completed!\")\n",
    "print(\"\\nüì• Next steps:\")\n",
    "print(\"1. Download 'generator_model.pth' from the files panel (left sidebar)\")\n",
    "print(\"2. Upload it to your Streamlit app repository\")\n",
    "print(\"3. Deploy your app on Streamlit Cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da5802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download instructions\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üì• Downloading the trained model...\")\n",
    "files.download('generator_model.pth')\n",
    "print(\"‚úÖ Download started! Check your browser's download folder.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
